{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17f1048e",
   "metadata": {},
   "source": [
    "# Data Cleaning:\n",
    "\n",
    "Data cleaning (or data cleansing) is the process of identifying, correcting, and removing errors, inconsistencies, and inaccuracies in data to ensure its quality and usability for analysis.\n",
    "It is a crucial step in data preprocessing to prepare raw data for further analysis or machine learning tasks.\n",
    "\n",
    "- Improves Accuracy: Clean data ensures that your analysis or models are based on accurate and reliable information.\n",
    "- Enhances Consistency: Consistent data across different sources or within a dataset is critical for meaningful comparisons and insights.\n",
    "- Reduces Errors: Cleaning data helps to minimize errors that could lead to incorrect conclusions or predictions.\n",
    "\n",
    "## Common Steps in Data Cleaning:\n",
    "\n",
    "##### 1. Handling Missing Data:\n",
    "- Identify Missing Values: Detect missing or null values in the dataset.\n",
    "- Imputation: Fill missing values using methods like mean, median, mode, or more advanced techniques like K-Nearest Neighbors (KNN) imputation.\n",
    "- Removal: If a large portion of a row or column has missing data, you might decide to remove it entirely.\n",
    "\n",
    "##### 2. Removing Duplicates:\n",
    "- Identify Duplicates: Find duplicate records in the dataset.\n",
    "- Remove Duplicates: Drop the duplicate rows to avoid skewed analysis results.\n",
    "\n",
    "##### 3. Correcting Inconsistencies:\n",
    "- Standardizing Formats: Ensure that data formats (e.g., date formats, text case) are consistent across the dataset.\n",
    "- Unifying Categories: Merge similar but differently labeled categories (e.g., \"USA,\" \"United States,\" \"US\" should be standardized to one label).\n",
    "\n",
    "##### 4. Outlier Detection and Treatment:\n",
    "- Identify Outliers: Detect data points that significantly differ from the rest of the dataset using statistical methods like Z-scores or the IQR method.\n",
    "- Treat Outliers: Depending on the context, you can either remove outliers, cap them at a threshold, or analyze them separately.\n",
    "\n",
    "##### 5. Handling Incorrect Data:\n",
    "- Identify Errors: Detect data entry errors, typos, or logically inconsistent values (e.g., a negative age).\n",
    "- Correct Errors: Fix or remove incorrect data points based on domain knowledge or by referencing authoritative sources.\n",
    "\n",
    "##### 6. Converting Data Types:\n",
    "- Data Type Consistency: Ensure that the data types (e.g., integers, floats, strings) are consistent and appropriate for each column.\n",
    "- Conversion: Convert columns to the correct data types as needed.\n",
    "\n",
    "##### 7. Data Normalization and Scaling:\n",
    "- Normalization: Adjust the range of numerical data (e.g., scaling between 0 and 1) to ensure that different features are comparable.\n",
    "- Standardization: Standardize features by removing the mean and scaling to unit variance.\n",
    "\n",
    "##### 8. Addressing Imbalanced Data:\n",
    "- Balancing Classes: If you're working with classification tasks, ensure that the dataset has a balanced distribution of classes. This might involve techniques like oversampling the minority class or undersampling the majority class.\n",
    "\n",
    "\n",
    "## Tools and Libraries for Data Cleaning:\n",
    "#### Python Libraries: \n",
    "Pandas, NumPy, SciPy, and Scikit-learn offer powerful tools for data cleaning.\n",
    "#### Data Cleaning Tools: \n",
    "OpenRefine, Trifacta, Talend, and DataWrangler are specialized tools designed for more extensive or complex data cleaning tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da813276",
   "metadata": {},
   "source": [
    "## NumPy (import numpy as np):\n",
    "NumPy is a library for numerical computing in Python. It provides support for large multi-dimensional arrays and matrices, along with a collection of mathematical functions to operate on these arrays.\n",
    "\n",
    "- np is an alias commonly used to refer to NumPy functions and objects. \n",
    "\n",
    "You can perform operations like array creation, mathematical calculations, linear algebra, random number generation, and more using NumPy.\n",
    "\n",
    "## Pandas (import pandas as pd):\n",
    "\n",
    "Pandas is a library for data manipulation and analysis in Python. It provides data structures like Series (1D) and DataFrame (2D) for handling and analyzing structured data.\n",
    "\n",
    "- pd is an alias commonly used to refer to Pandas functions and objects. \n",
    "\n",
    "You can use Pandas to load data from various file formats (e.g., CSV, Excel), clean and transform data, perform data analysis, and visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49a11b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0249f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': ['Alice', 'Bob', 'Charlie', 'David', 'Emily', 'Frank', 'Grace'], 'age': [25, 30, nan, 'thirty-five', 22, 45, 'unknown'], 'gender': ['Female', 'Male', 'Male', 'Male', 'Female', 'Other', 'Male'], 'country': ['USA', 'Canada', 'Mexico', 'USA', 'Australia', 'Unknown', 'UK'], 'monthly_salary': [50000, 75000, '60k', nan, 40000, 'unknown', 80000], 'annual_income': ['60,000', '90,000', nan, '100,000', '40k', '75k', 'unknown']}\n",
      "\n",
      "      name          age  gender    country monthly_salary annual_income\n",
      "0    Alice           25  Female        USA          50000        60,000\n",
      "1      Bob           30    Male     Canada          75000        90,000\n",
      "2  Charlie          NaN    Male     Mexico            60k           NaN\n",
      "3    David  thirty-five    Male        USA            NaN       100,000\n",
      "4    Emily           22  Female  Australia          40000           40k\n",
      "5    Frank           45   Other    Unknown        unknown           75k\n",
      "6    Grace      unknown    Male         UK          80000       unknown\n"
     ]
    }
   ],
   "source": [
    "messy_data = {\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David', 'Emily', 'Frank', 'Grace'],\n",
    "    'age': [25, 30, np.nan, 'thirty-five', 22, 45, 'unknown'],\n",
    "    'gender': ['Female', 'Male', 'Male', 'Male', 'Female', 'Other', 'Male'],\n",
    "    'country': ['USA', 'Canada', 'Mexico', 'USA', 'Australia', 'Unknown', 'UK'],\n",
    "    'monthly_salary': [50000, 75000, '60k', np.nan, 40000, 'unknown', 80000],\n",
    "    'annual_income': ['60,000', '90,000', np.nan, '100,000', '40k', '75k', 'unknown']\n",
    "}\n",
    "\n",
    "# Import messy data into a Pandas DataFrame\n",
    "messy_df = pd.DataFrame(messy_data)\n",
    "\n",
    "print(messy_data)\n",
    "print()\n",
    "print(messy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9de36c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      name   age  gender    country monthly_salary annual_income\n",
      "0    Alice  25.0  Female        USA          50000        60,000\n",
      "1      Bob  30.0    Male     Canada          75000        90,000\n",
      "2  Charlie  30.0    Male     Mexico            60k           NaN\n",
      "3    David  35.0    Male        USA            NaN       100,000\n",
      "4    Emily  22.0  Female  Australia          40000           40k\n",
      "5    Frank  45.0   Other    Unknown        unknown           75k\n",
      "6    Grace  30.0    Male         UK          80000       unknown\n"
     ]
    }
   ],
   "source": [
    "# Handling non-numeric data types and missing values:\n",
    "messy_df['age'] = pd.to_numeric(messy_df['age'].replace('thirty-five', 35), errors='coerce')\n",
    "messy_df['age'].fillna(messy_df['age'].median(), inplace=True)\n",
    "messy_df.fillna({'country': 'Unknown', 'gender': 'Other'}, inplace=True)\n",
    "print(messy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed34938e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      name   age  gender    country monthly_salary  annual_income\n",
      "0    Alice  25.0  Female        USA          50000     60000000.0\n",
      "1      Bob  30.0    Male     Canada          75000     90000000.0\n",
      "2  Charlie  30.0    Male     Mexico            60k            NaN\n",
      "3    David  35.0    Male        USA            NaN    100000000.0\n",
      "4    Emily  22.0  Female  Australia          40000        40000.0\n",
      "5    Frank  45.0   Other    Unknown        unknown        75000.0\n",
      "6    Grace  30.0    Male         UK          80000            NaN\n"
     ]
    }
   ],
   "source": [
    "# Handling inconsistent annual income format:\n",
    "messy_df['annual_income'] = pd.to_numeric(messy_df['annual_income'].str.replace('[^\\d.]', '', regex=True), errors='coerce')\n",
    "messy_df['annual_income'] *= 1000  # Multiply by 1000 to convert 'k' to 000\n",
    "print(messy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f0f7075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      name   age      gender    country  annual_income\n",
      "0    Alice  25.0      Female        USA     60000000.0\n",
      "1      Bob  30.0        Male     Canada     90000000.0\n",
      "2  Charlie  30.0        Male     Mexico            NaN\n",
      "3    David  35.0        Male        USA    100000000.0\n",
      "4    Emily  22.0      Female  Australia        40000.0\n",
      "5    Frank  45.0  Non-binary    Unknown        75000.0\n",
      "6    Grace  30.0        Male         UK            NaN\n"
     ]
    }
   ],
   "source": [
    "# Remove dependent column\n",
    "messy_df.drop('monthly_salary', axis=1, inplace=True)\n",
    "\n",
    "# Convert 'Other' to 'Non-binary'\n",
    "messy_df['gender'].replace('Other', 'Non-binary', inplace=True)\n",
    "print(messy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "094f845c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL DATA:\n",
      "{'name': ['Alice', 'Bob', 'Charlie', 'David', 'Emily', 'Frank', 'Grace'], 'age': [25, 30, nan, 'thirty-five', 22, 45, 'unknown'], 'gender': ['Female', 'Male', 'Male', 'Male', 'Female', 'Other', 'Male'], 'country': ['USA', 'Canada', 'Mexico', 'USA', 'Australia', 'Unknown', 'UK'], 'monthly_salary': [50000, 75000, '60k', nan, 40000, 'unknown', 80000], 'annual_income': ['60,000', '90,000', nan, '100,000', '40k', '75k', 'unknown']}\n",
      "\n",
      "CLEANED DATA:\n",
      "      name   age      gender    country  annual_income\n",
      "0    Alice  25.0      Female        USA     60000000.0\n",
      "1      Bob  30.0        Male     Canada     90000000.0\n",
      "2  Charlie  30.0        Male     Mexico            NaN\n",
      "3    David  35.0        Male        USA    100000000.0\n",
      "4    Emily  22.0      Female  Australia        40000.0\n",
      "5    Frank  45.0  Non-binary    Unknown        75000.0\n",
      "6    Grace  30.0        Male         UK            NaN\n"
     ]
    }
   ],
   "source": [
    "print(\"ORIGINAL DATA:\")\n",
    "print(messy_data)\n",
    "print()\n",
    "print(\"CLEANED DATA:\")\n",
    "print(messy_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40b718e",
   "metadata": {},
   "source": [
    "## Summary:\n",
    "\n",
    "In this code, we start by importing a dictionary of messy data into a Pandas DataFrame. The data includes various inconsistencies, such as missing values (`np.nan`), non-numeric entries (e.g., `\"thirty-five\"` for age and `\"60k\"` for salary), and inconsistent formats (e.g., `\"40k\"` vs. `\"75k\"` for income). The initial steps focus on cleaning this data. We convert the `age` column to numeric values, replacing non-numeric entries with their correct values (e.g., replacing `\"thirty-five\"` with `35`) and then imputing the missing values with the median age. Similarly, missing values in the `country` and `gender` columns are filled with `'Unknown'` and `'Other'`, respectively.\n",
    "\n",
    "Next, we clean up the `annual_income` column by removing non-numeric characters and converting the income values to a consistent numeric format (e.g., converting `'75k'` to `75000`). The `monthly_salary` column is dropped since it may be redundant, and the `gender` column's `'Other'` entries are standardized to `'Non-binary'` for consistency. After these cleaning steps, the cleaned data is printed, showing a more uniform and accurate DataFrame compared to the original messy data. The code demonstrates how to handle missing values, convert inconsistent data formats, and standardize categorical variables in a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529691ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
